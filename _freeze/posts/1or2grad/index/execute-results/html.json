{
  "hash": "a4b7ec9e3e964980dde4ae0b974c496a",
  "result": {
    "markdown": "---\ntitle: A thing or two about gradient\nsubtitle: From an interesting internship post\nauthor: Pham Nguyen Hung\ndraft: false\ndate: '2022-12-18'\ncategories:\n  - code\nformat:\n  html:\n    toc: true\n    code-fold: false\n    highlight-style: pygments\n---\n\nWhile scrolling through LinkedIn, I found this curious requirement for the machine learning engineer intern position:\n![](Screenshot 2022-12-18 at 12-07-18 (7) data scientist intern Jobs in Singapore LinkedIn.png)\n\nTo be honest, I have no idea what is \"gradient taping\", though I vaguely remember that TensorFlow has a [tf.GradientTape()](https://www.tensorflow.org/api_docs/python/tf/GradientTape) class. And yes, it does. So what exactly is a gradient tape, and why do we need it?\n\n# Machine learning and gradient:\nIn machine learning, you have a *model*, which takes in *inputs* a.k.a *data* and gives *outputs* a.k.a *predictions*. A *loss function*, whose value depends on the *parameters* of your model, measures the difference between the predictions and the actual results. \"Training a model\" describes the process where you run an algorithm to change the parameters such as the loss function reaches a minimum. The algorithm you run is typically *gradient descent*, which involves calculating the *gradient* of the loss function with respect to (w.r.t) each parameter a.k.a *how the loss function would change* and *in what direction* if you increases the parameter. The takeaway points are: 1) calculating gradient is very important and 2) if the paragraph above does not make sense, you should go back and check out a beginner's machine learning course.\n\nGiven you have taken that beginner's course, you would remember that the formula to calculate the gradient for linear or logistic regression is fairly straightforward and you could even use Numpy. However, for deep neural networks, with the current extreme case of any GPT models, the formula is very forbidding. We need a more general approach, and that was when we received *backpropagation*.\n![Try finding the gradients for all 6 billion parameters of GPT-J](GPT-vs-GPT-J-uai-1440x933.webp)\n\n# Backpropagation, or Autodifferentiation, or GradientTape, or Autograd, or...\nYou probably have heard/will need to Google the *chain rule* in calculus. In lay terms, it just means that \"you can treat gradient just like fractions\". For example, in general case, if we have $z$ whose value partly depends on $y$, and $y$ whose value partly depends on $x$, then the gradient of z w.r.t to x is\n$$\\frac{\\delta z}{\\delta x} = \\frac{\\delta z}{\\delta y}*\\frac{\\delta y}{\\delta x}$$\njust like with normal fractions.\n\nThis formula holds for as many relationships as it could get, not just 2 like here. In a neural network, we have parameters in layers, and the output value of each layer depends partly on the output value of the last layer. This means that if we can keep track of all the operations in the forward calculation (passing the data through the layers, one at a time), we can calculate the gradient for each parameter, also one layer at a time. That is the essential of backpropagation. And this is when tf.GradientTape comes in: this \"tape\" keeps track of all the operations to a particular variable, and helps you calculate the gradient value of any variable w.r.t to that variable.\n> For a detailed explanation of backpropagation, check out the [notes](https://cs231n.github.io/optimization-2/) and [lecture](https://www.youtube.com/watch?v=59Hbtz7XgjM) from CS231n, Stanford.\n\nHere is the example from [TensorFlow documentation](https://www.tensorflow.org/api_docs/python/tf/GradientTape):\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport tensorflow as tf\nx = tf.constant(3.0)\nwith tf.GradientTape() as g:\n    g.watch(x)\n    y = x * x\ndy_dx = g.gradient(y, x)\nprint(dy_dx)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntf.Tensor(6.0, shape=(), dtype=float32)\n```\n:::\n:::\n\n\nSo that's it for gradient taping - it's a way to keep track of the operations on a variable, which is used to calculate the gradient in backpropagation time. Most major framework, such as TensorFlow, have a way to implement this, so you don't need to do that from scratch (if you are interested in doing so, check out this [tutorial](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)), you just need to know how to use them. For example, this is a code block in PyTorch, another popular deep learning framework, that does the exact same thing:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport torch\nx = torch.tensor([3.], requires_grad=True)\ny = x*x\ndy_dx = torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y))\nprint(dy_dx)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(tensor([6.]),)\n```\n:::\n:::\n\n\nWe could also store the gradient value in the `.grad` attribute of variable `x`:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport torch\nx = torch.tensor([3.], requires_grad=True)\ny = x*x\ny.backward()\nprint(x.grad)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor([6.])\n```\n:::\n:::\n\n\nThe second way is more commonly seen in model training.\n\n## Image Credits:\nFrom top to bottom:\n\n1. This [internship post](https://www.linkedin.com/jobs/search/?currentJobId=3389948741&f_C=18706840&f_E=1&geoId=102454443&keywords=machine%20learning%20engineer&location=Singapore&refresh=true&position=1&pageNum=0) by Datature.\n2. This [blog post](https://www.cerebras.net/blog/cerebras-makes-it-easy-to-harness-the-predictive-power-of-gpt-j) on Cerebras\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}