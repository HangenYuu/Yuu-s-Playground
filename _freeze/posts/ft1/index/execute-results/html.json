{
  "hash": "0632558d79549bed8192c48893d9098a",
  "result": {
    "markdown": "---\ntitle: First thing (1)\nsubtitle: Data Analyst and Data Engineer\nauthor: Pham Nguyen Hung\ndraft: false\ndate: '2022-12-14'\ncategories:\n  - basic\nformat:\n  html:\n    toc: true\n    code-fold: true\n    css: styles.css\n---\n\n![](72vazj.jpg)\n\n# Motivation:\n\nThe idea for the post was stumbled during my job search, when I confused \"Data Scientist\" and \"Machine Learning Engineer\" (and \"Data Analyst\" and \"Data Engineer\", to a lesser extent) together so many times. The post was created so that nobody having read it in the near future got confused again.\n\nNow let's look at some internships from TikTok on LinkedIn, the company I am eyeing at. These job posts have high requirements for candidates and should be a good ceiling.\n\n# The easily distinguished jobs:\n\n## Data Analyst:\n![](Screenshot 2022-12-13 at 13-40-55 (18) data analyst intern Jobs LinkedIn.png)\n\nHere is a diagram from DataCamp that sums up the job descriptions well:             \n![](image1_7987ef4fa0.png)\n\nI will analyze the job descriptions from the angle of someone seeking employment as soon as possible, and that is the meaning of \"for our purpose\" below.\nFrom the job descriptions, you will need to know...\n\nBasic:\n\n1. ...how to use a business intelligence platforms - Looker, Power BI, Tableau and the like. The platform allows you to achieve step 2-4 in the above diagram. Take Power BI. You can prepare and transform data; you can explore data from basic (mean, median, etc.) to complex operations that you define yourself; you can do all kinds of visualizations; you can publish the findings to a report, an app (possibly dashboard), or slides to aid your presentation (more on that below). The most effective way to learn the tool for our purpose is through projects and just-in-time learning. You can find resources on this elsewhere so I will stop here.\n2. ...how to communicate (written and oral). After analyzing the data, of course you will need to present insights to \"stakeholders\" and your superiors. Because ~~nobody likes meeting~~time is precious, \"concise\" and \"easy to understand\" are good traits to have. For our purpose, the most impressive will be writing a documentation for an open-source project that we start or contribute significantly (enough that leads to change in documentation). A lesser one is keeping a blog that you write daily.\n\nPreferred:\nThese are specific TikTok's preferences:\n\n3. ...how to do statistical analysis. This is arguably \"basic\", not \"preferred\". The numbers you calculate in the platform, they all have statistical meanings, so it helps to know what you are calculating. In short, statistics is fundamental, so learn it well from the resource you prefer. (You can now find a playlist of entire university course or free textbook online).\n4. ...how to use API. A business intelligence platform can do all things, except generating initial data - you will need to load them in yourself. For TikTok, the data seem to be stored in a cloud database, so you will need to use API to pull them down. The best way to learn is through experimenting. For me, I used API to [convert ebook for my Kindle](https://developers.zamzar.com/) and [create movie ratings and recommendation](https://github.com/HangenYuu/Coursera-Python3_Programming-Final_Project/blob/main/Movie_Recommendation_With_API.ipynb). Side note: API is often used with a programming language, so you should learn some basic syntax for one. Python is a good choice for beginner.\n5. ...how to use Hadoop-related technology. Apache Hadoop is an open-source framework specialized in handling big data, especially in batch. Hadoop Distributed File System (HDFS), as the name suggests, help you work with data that are distributed across different databases. A company using Hadoop suggests a large volume of data (and facilities to store them), which is certainly the case at TikTok - just imagine how many reels are uploaded per day. And this is a company-specific preference: not all companies have data so big that Hadoop is required. But if you think that knowing Hadoop is beneficial in this age of big data, you can learn it. Make sure to focus on your job - data extraction, data preparation, etc.\n\n## Data Engineer:\nAs a [LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:6991442210093219840/) post suggested, data engineers are important. A data pipeline must exists before any analysis can be done. So I put here two internship posts:\n![](Screenshot 2022-12-14 at 09-39-55 (18) data engineer Jobs LinkedIn.png)\n![](Screenshot 2022-12-14 at 09-41-06 (18) data engineer Jobs LinkedIn.png)\n\nBefore continuing, let's me clarify that data engineer is not my current path, so I do not know the topics I mention well. There are people who are more qualified than me out there (especially on YouTube), seek them for further details.\nFrom the job descriptions, you will need to know...\n\n1. ...SQL. The language of database. MySQL is the place to start (YouTube uses that), and you can find free courses on Kaggle and practices on [StrataScratch](https://www.stratascratch.com/). But remember the emphasis on related project experience.\n2. ...one or more in Java/Go/C++/C#/Python. There is no \"supreme language\", use the one that you feel confident about. Again, remember the empahsis on \"software development\"/\"capabilities and mastering\" - it means project(s).\n3. ...data structures & algorithms. Some would say one word: LeetCode, but I would say two: \"explain LeetCode\". Your DSA will be measured in the coding questions, and you must make sure to solve them. However, notice the emphasis on \"communication skills\" - you also need to explain your solution in the simplest way possible.\n4. ...data warehouse/ETL development/data model/(data analysis/ecommerce). Extract Transform Load (ETL) is the basic job of data engineers: extract data from source(s), transform them based on requirement, and load the data into systems so that end-users can access. Data warehouse obviously stores data, but it needs designing based on your company's needs. E-commerce is company's specific needs. For data analysis appearance in data engineer's descriptions, I will treat it below.\n5. ...Hadoop ecosystem/open-source big data. These are again company's specific needs. Instead of going into details, let's remind the job seekers that each of these tech stacks is for a different problem, so trying to know all of the Apache family is inferior to knowing what your company requires.\n\n# Confusion, and introduction to the next post:\nNow, let's go back to \"data analysis in data engineer job\", and \"Hadoop in data analyst\". This is why I am initially confused: there is no definite boundary on the job descriptions. This inevitably will exist. For example, the company may be small, so data analysts are responsible for designing the data pipeline. At bigger companies, the roles are separated, but how shoudl data engineers design the pipeline? Based on data analysts' needs, of course, so it is beneficial that data engineers know data analysis to facilitate communication. And if data analysts know how to pull data directly from the company's Hadoop cluster, then it is less job for the data engineers, and so on. The lesson to us job seekers is 1) study your company, know its needs (often with the help of imagination) and 2) don't confine your knowledge to your job title, expand it to the ones that you (hopefully will) work closely with.\nIn the next post, I will treat two titles that even overlap more: data scientists and machine learning engineers. \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}